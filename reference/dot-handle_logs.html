<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Import and Store Scraping Log Files — .handle_logs • taRantula</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Import and Store Scraping Log Files — .handle_logs"><meta name="description" content="Reads individual progress log files generated during scraping, parses
their contents, and inserts the collected entries into the logs table
of the DuckDB results database.
After successful insertion, processed log files are removed from the
filesystem."><meta property="og:description" content="Reads individual progress log files generated during scraping, parses
their contents, and inserts the collected entries into the logs table
of the DuckDB results database.
After successful insertion, processed log files are removed from the
filesystem."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">taRantula</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/Intro.html">Get Started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://github.com/statistikat/taRantula/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Import and Store Scraping Log Files</h1>
      <small class="dont-index">Source: <a href="https://github.com/statistikat/taRantula/blob/master/R/UrlScraper_utils_logs.R" class="external-link"><code>R/UrlScraper_utils_logs.R</code></a></small>
      <div class="d-none name"><code>dot-handle_logs.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Reads individual progress log files generated during scraping, parses
their contents, and inserts the collected entries into the <code>logs</code> table
of the DuckDB results database.
After successful insertion, processed log files are removed from the
filesystem.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">.handle_logs</span><span class="op">(</span><span class="va">progress_dir</span>, <span class="va">db_file</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-progress-dir">progress_dir<a class="anchor" aria-label="anchor" href="#arg-progress-dir"></a></dt>
<dd><p>Path to the directory containing log files produced
during scraping.</p></dd>


<dt id="arg-db-file">db_file<a class="anchor" aria-label="anchor" href="#arg-db-file"></a></dt>
<dd><p>Path to the DuckDB database file where logs should be stored.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>Invisibly returns <code>TRUE</code> after logs have been imported and (if possible) the
corresponding files removed.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The function performs the following actions:</p><ul><li><p>Scans the <code>progress_dir</code> for log files created by parallel scraper workers</p></li>
<li><p>Parses each log file line‑by‑line, splitting entries into:</p><ul><li><p>timestamp</p></li>
<li><p>chunk/work‑unit identifier</p></li>
<li><p>URL currently being processed</p></li>
</ul></li>
<li><p>Converts parsed entries into a data frame suitable for database storage</p></li>
<li><p>Inserts all log entries into the DuckDB <code>logs</code> table using
<code>"INSERT OR IGNORE"</code> to avoid duplicates</p></li>
<li><p>Removes successfully processed log files</p></li>
</ul><p>Log files are expected to contain tab‑separated entries created by worker
processes. Files that are empty or unreadable are automatically discarded.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index">
<ul><li><p>The <code>logs</code> table created in the scraper database structure</p></li>
<li><p>Worker‑level logging functions within the scraper implementation</p></li>
</ul></div>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Statistics Austria</p>
</div>

<div class="pkgdown-footer-right">
  <p>Built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a>.</p>
</div>

    </footer></div>





  </body></html>

